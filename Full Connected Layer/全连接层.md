即 ==Fully Connected Feed-Forward Layer==

在神经网络中，将一个神经元的输出记为$a^l_{i}$，其中$l$指的是第$l$层神经网络，$i$指的是第$i$个神经元；那么对于一层的神经元，其输出则是一个**向量**，将这个向量记为$a^l$

### 参数详解
全连接层的含义即是所有的神经元都两两相接<br>
![全连接示意图](../Excalidraw/全连接层示意图)
图中出现了$w^l_{ij}$，表示的是层$l-1$与层$l$之间的权重，下标表示从神经元$j$到神经元$i$的传递权重(**反向传播的下标方向**)

这样，我们可以得到一个矩阵$W^l$，其可以表示为$$W^l=\begin{bmatrix}w^l_{11}&w^l_{12}&...& \\ w^l_{21}&w^l_{22}&...& \\...&...&...\end{bmatrix}$$其行数为$N_l$，列数为$N_{l-1}$

同时，每层神经网络都会存在**bias(偏差)**，一般会用$b^l$这个向量来表示，具体为$$b^l=\begin{bmatrix}b^l_{1}\\b^l_{2}\\...\\b^l_{i}\\...\end{bmatrix}$$表示为第$l$层的偏差

引入$z^l_i$来表示第$l$层第$i$个神经元的**激活输入**，用向量$z^l$表示第$l$层的所有神经元的激活输入，存在关系$$z^l=W^la^{l-1}+b^l$$

假定神经元的**激活函数**为$\sigma()$，则就会存在如下关系$$a^l=\sigma(z^l)$$

现在，就获得了完整的关系$$a^l=\sigma(W^la^{l-1}+b^l)$$

